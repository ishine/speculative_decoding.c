
#include <math.h>
#include <stdio.h>
#include <stdlib.h>
#include <string.h>

#include "run.c"

typedef struct {
    int *tokens;
    int length;
} SDTokens;

// single speculative decoding step
// called after prompt tokens are processed on both base and draft models
// returns list of tokens generated by speculative decoding step
SDTokens *sd_step(Transformer *base_model, Transformer *draft_model, Sampler *sampler, int pos, int steps) {
    if (steps <= 0) {
        return NULL;
    }
    int draft_steps = steps - 1; // number of draft tokens to generate
    if (draft_steps <= 0) {
        // sample from base
        int next = sample(sampler, base_model->state.logit_cache + base_model->config.vocab_size * (pos - 1));
        // advance the transformer for the next token
        forward(draft_model, &next, 1, pos);
        forward(base_model, &next, 1, pos);
        // construct result
        SDTokens *ret = (SDTokens*)malloc(sizeof(SDTokens));
        ret->length = 1;
        ret->tokens = (int*)malloc(sizeof(int));
        ret->tokens[0] = next;
        return ret;
    }
    
    // store draft model logits for speculative verification
    int* drafted_tokens = (int*)malloc(draft_steps * sizeof(int));
    float* draft_logit_cache = draft_model->state.logit_cache + (pos - 1) * draft_model->config.vocab_size;
    float* base_logit_cache = base_model->state.logit_cache + (pos - 1) * base_model->config.vocab_size;
    int idx = 0;     // current draft token index -> position in sequence = pos + idx
    int next = 0;    // will store the next token in the sequence
    while (idx < draft_steps) {
        // sample the next token from the logits
        next = sample(sampler, draft_logit_cache + idx * draft_model->config.vocab_size);
        drafted_tokens[idx] = next;

        // data-dependent terminating condition: the BOS (=1) token delimits sequences
        if (next == 1) { draft_steps = idx + 1; break; }

        // forward the transformer to get logits for the next token
        forward(draft_model, &next, 1, pos + idx);
        idx++;
    }
    // evaluate drafted tokens on base model (batched evaluation)
    forward(base_model, drafted_tokens, draft_steps, pos);

    // verify draft tokens based on saved logits
    int accepted = 0; // number of accepted draft tokens
    float *mp, *mq;
    for (int i = 0; i < draft_steps; i++) {
        mp = base_logit_cache + i * base_model->config.vocab_size;
        mq = draft_logit_cache + i * draft_model->config.vocab_size;
        // softmax(mp, base_model->config.vocab_size);
        // softmax(mq, draft_model->config.vocab_size);
        float p = mp[drafted_tokens[i]];
        float q = mq[drafted_tokens[i]];
        if (q <= p) {
            // keep the token
        } else {
            // reject token with probability 1 - p/q
            // flip a (float) coin (this is our source of entropy for sampling)
            float coin = random_f32(&sampler->rng_state);
            if (coin > p / q) {
                // reject the token
                break;
            }
        }
        accepted++;
    }

    // if not all draft tokens were accepted, calculate residual distribution for mp
    if (draft_steps > 0 && accepted != draft_steps) {
        float res_total = 0.0;
        for (int i = 0; i < base_model->config.vocab_size; i++) {
            float p = mp[i];
            float q = mq[i];
            mp[i] = fmaxf(p - q, 0.0);
            res_total += mp[i];
        }
        // normalize residual distribution
        for (int i = 0; i < base_model->config.vocab_size; i++) {
            mp[i] /= res_total;
        }   
    } else if (accepted == draft_steps) {
        mp = base_logit_cache + draft_steps * base_model->config.vocab_size;
        // softmax(mp, base_model->config.vocab_size);
    }

    // sample base model to get the next token
    float coin = random_f32(&sampler->rng_state);
    int next_base = sample_mult(mp, base_model->config.vocab_size, coin);

    // advance base and draft model for base model generated token
    forward(draft_model, &next_base, 1, pos + accepted);
    forward(base_model, &next_base, 1, pos + accepted);

    // construct result
    SDTokens *ret = (SDTokens*)malloc(sizeof(SDTokens));
    ret->length = accepted + 1;
    ret->tokens = (int*)malloc(ret->length * sizeof(int));
    for (int i = 0; i < accepted; i++) {
        ret->tokens[i] = drafted_tokens[i];
    }
    ret->tokens[accepted] = next_base;

    // free memory
    free(drafted_tokens);
    
    // return the result
    return ret;
}

void safe_printf_color(char *piece, int color) {
    // piece might be a raw byte token, and we only want to print printable chars or whitespace
    // because some of the other bytes can be various control codes, backspace, etc.
    if (piece == NULL) { return; }
    if (piece[0] == '\0') { return; }
    if (piece[1] == '\0') {
        unsigned char byte_val = piece[0];
        if (!(isprint(byte_val) || isspace(byte_val))) {
            return; // bad byte, don't print it
        }
    }
    // print with color
    printf("\033[38;5;%dm%s\033[0m", color, piece);
}

void sd_generate(Transformer *base_model, Transformer *draft_model, Tokenizer *tokenizer, Sampler *sampler, char *prompt, int steps) {
    char *empty_prompt = "";
    if (prompt == NULL) { prompt = empty_prompt; }

    // encode the (string) prompt into tokens sequence
    int num_prompt_tokens = 0;
    int* prompt_tokens = (int*)malloc((strlen(prompt)+3) * sizeof(int)); // +3 for '\0', ?BOS, ?EOS
    encode(tokenizer, prompt, 1, 0, prompt_tokens, &num_prompt_tokens);
    if (num_prompt_tokens < 1) {
        fprintf(stderr, "something is wrong, expected at least 1 prompt token\n");
        exit(EXIT_FAILURE);
    }

    int next;        // will store the next token in the sequence
    int token = prompt_tokens[0]; // kick off with the first token in the prompt
    int pos = 0;     // position in the sequence

    // process prompt tokens on base & draft models
    while (pos < num_prompt_tokens - 1) {
        // forward the transformer to get logits for the next token
        forward(base_model, &token, 1, pos);
        forward(draft_model, &token, 1, pos);

        // advance the state machine
        next = prompt_tokens[pos + 1];
        pos++;

        // data-dependent terminating condition: the BOS (=1) token delimits sequences
        if (next == 1) { break; }

        // print the token as string, decode it with the Tokenizer object
        char* piece = decode(tokenizer, token, next);
        safe_printf(piece); // same as printf("%s", piece), but skips "unsafe" bytes
        fflush(stdout);
        token = next;
    }
    forward(base_model, &token, 1, pos);
    forward(draft_model, &token, 1, pos);
    
    int progress = 0;
    int draft_steps = 5; // number of steps to run for each speculative decoding step
    while (progress < steps) {
        // run speculative decoding step to generate tokens
        int pos = progress + num_prompt_tokens;
        // limit the number of draft steps to the remaining tokens to generate
        int next_draft_steps = steps - progress < draft_steps ? steps - progress : draft_steps;
        // limit the number of draft steps to the remaining tokens in total sequence length
        next_draft_steps = pos + next_draft_steps > base_model->config.seq_len ? base_model->config.seq_len - pos : next_draft_steps;
        if (next_draft_steps <= 0 || pos >= base_model->config.seq_len) {
            break; // no more tokens to generate
        }
        SDTokens* generated_tokens = sd_step(base_model, draft_model, sampler, pos, next_draft_steps);
        if (generated_tokens == NULL) {
            // print error message
            fprintf(stderr, "error: no tokens generated\n");
            exit(EXIT_FAILURE);
        }
        // print tokens
        int bos = 0;
        for (int i = 0; i < generated_tokens->length; i++) {
            char* piece = decode(tokenizer, token, generated_tokens->tokens[i]);
            token = generated_tokens->tokens[i];
            // data-dependent terminating condition: the BOS (=1) token delimits sequences
            if (token == 1) { bos = 1; break; }
            if (i == generated_tokens->length - 1) {
                safe_printf(piece); // last token in the sequence
            } else {
                safe_printf_color(piece, 202); 
            }
            fflush(stdout);
        }
        progress += generated_tokens->length;
        free(generated_tokens->tokens);
        free(generated_tokens);
        if (bos) { break; }
    }
    free(prompt_tokens);
}

void sd_chat(Transformer *base_model, Transformer *draft_model, Tokenizer *tokenizer, Sampler *sampler,
          char *cli_user_prompt, char *cli_system_prompt, int steps) {
    // TODO: implement chat mode
    fprintf(stderr, "chat mode not implemented yet\n");
}

void error_usage() {
    fprintf(stderr, "Usage:   run <checkpoint> [options]\n");
    fprintf(stderr, "Example: run model.bin -n 256 -i \"Once upon a time\"\n");
    fprintf(stderr, "Options:\n");
    fprintf(stderr, "  -m | --model <string>  path to base model checkpoint file\n");
    fprintf(stderr, "  -d | --draft <string>  path to draft model checkpoint file\n");
    fprintf(stderr, "  -t           <float>  temperature in [0,inf], default 1.0\n");
    fprintf(stderr, "  -p           <float>  p value in top-p (nucleus) sampling in [0,1] default 0.9\n");
    fprintf(stderr, "  -s           <int>    random seed, default time(NULL)\n");
    fprintf(stderr, "  -n           <int>    number of steps to run for, default 256. 0 = max_seq_len\n");
    fprintf(stderr, "  -i           <string> input prompt\n");
    fprintf(stderr, "  -z           <string> optional path to custom tokenizer\n");
    fprintf(stderr, "  -m           <string> mode: generate|chat, default: generate\n");
    fprintf(stderr, "  -y           <string> (optional) system prompt in chat mode\n");
    exit(EXIT_FAILURE);
}

int main(int argc, char *argv[]) {

    // default parameters
    char *base_model_path = NULL;  // e.g. out/model.bin
    char *draft_model_path = NULL; // e.g. out/model-draft.bin
    char *tokenizer_path = "tokenizer.bin";
    float temperature = 1.0f;   // 0.0 = greedy deterministic. 1.0 = original. don't set higher
    float topp = 0.9f;          // top-p in nucleus sampling. 1.0 = off. 0.9 works well, but slower
    int steps = 256;            // number of steps to run for
    char *prompt = NULL;        // prompt string
    unsigned long long rng_seed = 0; // seed rng with time by default
    char *mode = "generate";    // generate|chat
    char *system_prompt = NULL; // the (optional) system prompt to use in chat mode
    
    for (int i = 1; i < argc; i+=2) {
        // do some basic validation
        if (i + 1 >= argc) { error_usage(); } // must have arg after flag
        if (argv[i][0] != '-') { error_usage(); } // must start with dash
        if (strlen(argv[i]) != 2) { error_usage(); } // must be -x (one dash, one letter)
        // read in the args
        if (strcmp(argv[i], "--model") == 0 || strcmp(argv[i], "-m") == 0) {
            base_model_path = argv[i + 1];
        } else if (strcmp(argv[i], "--draft") == 0 || strcmp(argv[i], "-d") == 0) {
            draft_model_path = argv[i + 1];
        } else if (argv[i][1] == 't') { temperature = atof(argv[i + 1]); }
        else if (argv[i][1] == 'p') { topp = atof(argv[i + 1]); }
        else if (argv[i][1] == 's') { rng_seed = atoi(argv[i + 1]); }
        else if (argv[i][1] == 'n') { steps = atoi(argv[i + 1]); }
        else if (argv[i][1] == 'i') { prompt = argv[i + 1]; }
        else if (argv[i][1] == 'z') { tokenizer_path = argv[i + 1]; }
        else if (argv[i][1] == 'm') { mode = argv[i + 1]; }
        else if (argv[i][1] == 'y') { system_prompt = argv[i + 1]; }
        else { error_usage(); }
    }

    // parameter validation/overrides
    if (rng_seed <= 0) rng_seed = (unsigned int)time(NULL);
    if (temperature < 0.0) temperature = 0.0;
    if (topp < 0.0 || 1.0 < topp) topp = 0.9;
    if (steps < 0) steps = 0;

    // build the Transformer via the model .bin file
    Transformer base_model;
    build_transformer(&base_model, base_model_path);
    if (steps == 0 || steps > base_model.config.seq_len) steps = base_model.config.seq_len; // override to ~max length
    Transformer draft_model;
    // TODO: override draft model config.seq_len to provide enough kv cache space for longer sequences
    build_transformer(&draft_model, draft_model_path);
    // TODO: remove after seq_len override is implemented
    // For now, we constrain the number of steps to the minimum of the two models
    if (steps == 0 || steps > base_model.config.seq_len) steps = base_model.config.seq_len; // override to ~max length
    // assert vocab size match
    if (base_model.config.vocab_size != draft_model.config.vocab_size) {
        fprintf(stderr, "error: base and draft models have different vocab sizes\n");
        exit(EXIT_FAILURE);
    }

    // build the Tokenizer via the tokenizer .bin file
    Tokenizer tokenizer;
    build_tokenizer(&tokenizer, tokenizer_path, base_model.config.vocab_size);

    // build the Sampler
    Sampler sampler;
    build_sampler(&sampler, base_model.config.vocab_size, temperature, topp, rng_seed);
    
    // run!
    if (strcmp(mode, "generate") == 0) {
        sd_generate(&base_model, &draft_model, &tokenizer, &sampler, prompt, steps);
    } else if (strcmp(mode, "chat") == 0) { // FIXME: not implemented yet
        sd_chat(&base_model, &draft_model, &tokenizer, &sampler, prompt, system_prompt, steps);
    } else {
        fprintf(stderr, "unknown mode: %s\n", mode);
        error_usage();
    }

    // memory and file handles cleanup
    free_sampler(&sampler);
    free_tokenizer(&tokenizer);
    free_transformer(&base_model);
    free_transformer(&draft_model);
    return 0;
}